---
title: "SMDS Homework - Block 5"
author: "A. Carraro, P. Morichetti, and E. Ballarin  |  Group 'E'"
date: "22nd June 2020"
output:
  html_document:
    theme: darkly
    highlight: breezedark
    mathjax: default
    self_contained: true
    md_extensions: +autolink_bare_uris
    toc: true
    toc_collapsed: false
    toc_float: true
    toc_depth: 3
    number_sections: false
header-includes:
- \usepackage{color}
- \usepackage{graphicx}
- \usepackage{grffile}
institute: University of Trieste, SISSA, ICTP, University of Udine
graphics: yes
fontsize: 10pt
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.align = 'center', warning=FALSE, message=FALSE, fig.asp=0.625, dev='png', global.par = TRUE, dev.args=list(pointsize=10), fig.path = 'figs/')
```

```{r setup, include=FALSE}
library(knitr)
local({
  hook_plot = knit_hooks$get('plot')
  knit_hooks$set(plot = function(x, options) {
    paste0('\n\n----\n\n', hook_plot(x, options))
  })
})
```



# Exercises from *CS* 

## Exercise 1.3

### Text

Suppose that

$$
\boldsymbol{Y} \sim \mathcal{N} \left( \begin{bmatrix} 1\\ 2 \end{bmatrix} , \begin{bmatrix} 2 & 1\\ 1 & 2 \end{bmatrix} \right) \ .
$$

Find the conditional *p.d.f.* of $Y_1$, given that $Y_1 + Y_2 = 3$.


### Solution

We have that $\boldsymbol{Y} = (Y_1, Y_2)$, so $\boldsymbol{y} = (y_1, y_2)$, $\boldsymbol{\mu} = (E(Y_1), E(Y_2)) = \begin{bmatrix} 1\\ 2 \end{bmatrix}$ and $\boldsymbol{\Sigma} = \begin{bmatrix} Var(Y_1) & Cov(Y_1, Y_2) \\ Cov(Y_2, Y_1) & Var(Y_2) \end{bmatrix} = \begin{bmatrix} 2 & 1\\ 1 & 2 \end{bmatrix}$.

We compute

$$
\det(\boldsymbol\Sigma) = \begin{vmatrix} 2 & 1\\ 1 & 2 \end{vmatrix} = 2\cdot 2 - 1\cdot 1 = 4 - 1 = 3
$$
and
$$
\boldsymbol\Sigma^{-1} = \begin{bmatrix} 2 & 1\\ 1 & 2 \end{bmatrix}^{-1} = \begin{bmatrix} 2/3 & -1/3 \\ -1/3 & 2/3 \end{bmatrix}
$$
so
$$
\begin{align*}
(\boldsymbol y - \boldsymbol\mu)^T \boldsymbol\Sigma^{-1} (\boldsymbol y - \boldsymbol\mu) &= \begin{bmatrix} y_1 - 1, y_2 - 2 \end{bmatrix} \begin{bmatrix} 2 & 1\\ 1 & 2 \end{bmatrix}^{-1} \begin{bmatrix} y_1 - 1 \\ y_2 - 2 \end{bmatrix} \\
&= \begin{bmatrix} y_1 - 1, y_2 - 2 \end{bmatrix} \begin{bmatrix} 2/3 & -1/3 \\ -1/3 & 2/3 \end{bmatrix} \begin{bmatrix} y_1 - 1 \\ y_2 - 2 \end{bmatrix} \\
&=  \begin{bmatrix} \frac23 y_1 - \frac13 y_2 & -\frac13 y_1 + \frac23 y_2 -1 \end{bmatrix} \begin{bmatrix} y_1 - 1 \\ y_2 - 2 \end{bmatrix} \\
&= \frac23 (y_1^2 - y_1y_2 - 3y_2+ y_2^2 + 3) \\
&= \frac23 \left(y_1 - \frac{y_2}2 \right)^2 + \frac12 (y_2 - 2)^2
\end{align*}
$$
So we have that the joint distribution is

$$
\begin{align*}
f(\boldsymbol y = (y_1, y_2)) &= \frac1{\sqrt{(2 \pi)^2 \cdot \det(\boldsymbol\Sigma)}} \exp \left( -\frac12 (\boldsymbol y - \boldsymbol\mu)^T \boldsymbol\Sigma^{-1} (\boldsymbol y - \boldsymbol\mu) \right)\\
&= \frac1{\sqrt{(2 \pi)^2 \cdot 3}} \exp \left( -\frac12 \cdot \frac23 (y_1^2 - y_1y_2 - 3y_2+ y_2^2 + 3) \right)
\end{align*}
$$
Then the marginal distribution of $Y_2$ is

$$
\begin{align*}
f_2(y_2) &= \int_{-\infty}^{+\infty} f(\boldsymbol y) dy_1 = \int_{-\infty}^{+\infty} \frac1{\sqrt{(2 \pi)^2 \cdot \det(\boldsymbol\Sigma)}} \exp \left( -\frac12 (\boldsymbol y - \boldsymbol\mu)^T \boldsymbol\Sigma^{-1} (\boldsymbol y - \boldsymbol\mu) \right) dy_1 \\
&= \int_{-\infty}^{+\infty} \frac1{\sqrt{(2 \pi)^2 \cdot 3}} \exp \left( -\frac12 \cdot \left( \frac23 \left(y_1 - \frac{y_2}2 \right)^2 + \frac12 (y_2 - 2)^2 \right) \right) dy_1 \\
&= \int_{-\infty}^{+\infty} \frac1{\sqrt{2 \pi}} \exp \left( -\frac12 \frac23 \left(y_1 - \frac{y_2}2 \right)^2 \right) \frac1{\sqrt{2 \pi \cdot 3}} \exp \left( -\frac12 \frac{(y_2 - 2)^2}2 \right) dy_1 \\
&= \frac1{\sqrt{2 \pi \cdot 3}} \exp \left( -\frac12 \frac{(y_2 - 2)^2}2 \right) \sqrt{\frac32} \int_{-\infty}^{+\infty} \frac1{\sqrt{2 \pi 3/2}} \exp \left( -\frac12 \frac{(y_1 - y_2/2)^2}{3/2} \right) dy_1 \\
&= \frac{\sqrt{3/2}}{\sqrt{2 \pi \cdot 3}} \exp \left( -\frac12 \frac{(y_2 - 2)^2}2 \right) \cdot 1 = \frac1{\sqrt{2 \pi \cdot 2}} \exp \left( -\frac12 \frac{(y_2 - 2)^2}2 \right)
\end{align*}
$$

so $Y_2 \sim \mathcal{N}(2, 2)$. We then compute the conditional distribution of $Y_1$ given $Y_1 + Y_2 = 3$:

$$
\begin{align*}
f_1 (y_1 \mid y_1 + y_2 = 3) &= f_1 (y_1 \mid y_2 = 3 - y_1) = \frac{f(y_1, y_2 = 3 - y_1)}{f_2(y_2 = 3 - y_1)} \\
&= \frac{\frac1{\sqrt{(2 \pi)^2 \cdot 3}} \exp \left( -\frac12 \cdot \frac23 (y_1^2 - y_1(3 - y_1) - 3(3 - y_1) + (3 - y_1)^2 + 3) \right)}{\frac1{\sqrt{2 \pi \cdot 2}} \exp \left( -\frac12 \frac{(3 - y_1 - 2)^2}2 \right)} \\
&= \frac1{\sqrt{2 \pi \cdot 3/2}} \exp \left( -\frac13 (y_1^2 - 3y_1 + y_1^2 - 9 + 3y_1 + 9 - 6y_1 + y_1^2 + 3) + \frac14 (1 -2 y_1 + y_1^2) \right) \\
&= \frac1{\sqrt{3 \pi}} \exp \left( -y_1^2 + 2y_1 - 1 + \frac14 - \frac12 y_1 + \frac14 y_1^2 \right) = \frac1{\sqrt{3 \pi}} \exp \left( - \frac34 y_1^2 + \frac34 y_1 - \frac34 \right) \\
&= \frac1{\sqrt{3 \pi}} \exp \left( - \frac34 (y_1^2 - y_1 + 1) \right) \\
\end{align*}
$$



## Exercise 4.3

### Text

Random variables $\mathit{X}$ and $\mathit{Y}$ have joint *p.d.f.* $f(x,y) = kx^{\alpha}y^{\beta}$, $0 \leq x \leq 1$, $0 \leq y \leq 1$. Assume that you have $n$ independent pairs of observations $\left({ x_i, y_i }\right)$.  

(a) Evaluate $k$ in terms of $\alpha$ and $\beta$.  

(b) Find the maximum likelihood estimators of $\alpha$ and $\beta$.   

(c) Find approximate variances of $\hat{\alpha}$ and $\hat{\beta}$.   


### Solution

Probably just some $\LaTeX$.

<!--```{r cs_04_03, code = readLines("src/CS_04_03.R"), echo=TRUE}
```                                                                    -->

### Comments

Probably none.



# Exercises from *DAAG* 

## Exercise 4.5

### Text

The following code draws, in a $2 \times 2$ layout, $10$ boxplots of random samples of $1000$ from a normal distribution, $10$ boxplots of random samples of $1000$ from a $t$-distribution with $7$ *d.f.*, $10$ boxplots of random samples of $200$ from a normal distribution, and $10$ boxplots of random samples of $200$ from a $t$-distribution with $7$ *d.f.*:

```{r daag_04_05_text_01, echo=TRUE}
oldpar <- par(mfrow=c(2,2))

tenfold1000 <- rep(1:10, rep(1000,10))

boxplot(split(rnorm(1000*10), tenfold1000), ylab="normal - 1000")
boxplot(split(rt(1000*10, 7), tenfold1000),
    ylab=expression(t[7]*" - 1000"))

tenfold100 <- rep(1:10, rep(100, 10))

boxplot(split(rnorm(100*10), tenfold100), ylab="normal - 100")
boxplot(split(rt(100*10, 7), tenfold100),
    ylab=expression(t[7]*" - 100"))

par(oldpar)

```

Refer back to the discussion of heavy-tailed distributions in *DAAG, 3.2.2*, and comment on the different numbers and configurations of points that are flagged as possible outliers.

### Comments

Something.

## Exercise 11.5

### Text

This exercise will compare alternative measures of accuracy from $\mathsf{randomForest()}$ runs.  

First, $16$ rows where data (on `V6`) is missing will be omitted:  

```{r daag_11_05_text_01, echo=TRUE}
library(MASS)

sapply(MASS::biopsy, function(x)sum(is.na(x)))
biops <- na.omit(MASS::biopsy[,-1])    # Column 1 is ID

## Examine list element names in randomForest object
names(randomForest::randomForest(class~., data=biops))

sapply(MASS::biopsy, function(x)sum(is.na(x)))
biops <- na.omit(MASS::biopsy[,-1])    # Column 1 is ID

## Examine list element names in randomForest object
names(randomForest::randomForest(class~ ., data=biops))

```

(a) Compare repeated $\mathsf{randomForest()}$ runs:

```{r, echo=TRUE, eval=FALSE}
## Repeated runs, note variation in OOB accuracy.
for(i in 1:10) {
  biops.rf <- randomForest(class~ ., data=biops)
  OOBerr <- mean(biops.rf$err.rate[,"OOB"])
  
  print(paste(i, ": ", round(OOBerr, 4), sep=""))
  print(round(biops.rf$confusion, 4))
}
``` 

(b) Compare *OOB* accuracies with *test* set accuracies:

```{r, echo=TRUE, eval=FALSE}
## Repeated train/test splits: OOB accuracy vs test set accuracy.
for(i in 1:10){
  trRows <- sample(1:dim(biops)[1], size=round(dim(biops)[1]/2))
  biops.rf <- randomForest(class~ ., data=biops[trRows, ],
                           xtest=biops[-trRows,-10],
                           ytest=biops[-trRows,10])
  oobErr <- mean(biops.rf$err.rate[,"OOB"])
  testErr <- mean(biops.rf$test$err.rate[,"Test"])
  print(round(c(oobErr,testErr),4))
}
```

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Plot test set accuracies against OOB accuracies. Add the line `y = x` to the plot. Is there any consistent difference in the accuracies? Given a random training/test split, is there any reason to expect a consistent difference between OOB accuracy and test accuracy?

(c) Calculate the error rate for the training data:  

```{r, echo=TRUE, eval=FALSE}
randomForest(class~ ., data=biops, xtest=biops[,-10],
             ytest=biops[,10])
```

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Explain why use of the training data for testing leads to an error rate that is zero.

### Solution

(a) We compare repeated $\mathsf{randomForest()}$ runs:

```{r daag_11_05_text_02, echo=TRUE}
## Repeated runs, note variation in OOB accuracy.
OOBerr <- c()
for(i in 1:10) {
  biops.rf  <- randomForest::randomForest(class~ ., data=biops)
  OOBerr[i] <- mean(biops.rf$err.rate[,"OOB"])
  
  print(paste(i, ": OOB err = ", round(OOBerr[i], 4), sep=""))
  print(round(biops.rf$confusion, 4))
}
```  

```{r daag_11_05_text_02.5, echo=TRUE}
print(paste("The mean is", round(mean(OOBerr), 5), "while the variance is", round(var(OOBerr), 9)))
```

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can see that the OOB errors are more or less equal, with a mean of $0.029$ and a very little variance.


(b) We compare *OOB* accuracies with *test* set accuracies:

```{r daag_11_05_text_03, echo=TRUE}
## Repeated train/test splits: OOB accuracy vs test set accuracy.
oobErr <- c()
testErr <- c()
for(i in 1:10){
  trRows <- sample(1:dim(biops)[1], size=round(dim(biops)[1]/2))
  
  biops.rf <- randomForest::randomForest(class~ ., data=biops[trRows, ],
    xtest=biops[-trRows,-10],
    ytest=biops[-trRows,10])
  
  oobErr[i] <- mean(biops.rf$err.rate[,"OOB"])
  testErr[i] <- mean(biops.rf$test$err.rate[,"Test"])
  
  print(round(c(oobErr[i],testErr[i]),4))
}
```

```{r daag_11_05_text_03.5, echo=FALSE}
print(paste("The mean of the OOB error is", round(mean(oobErr), 5), "while the mean of the test error is", round(mean(testErr), 5)))
#print(paste("The variance between the two errors is", round(var(c(mean(oobErr), mean(testErr))), 6)))
```


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can see that the two test errors can be quite different from each other. Nontheless, the means are quite similar.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We plot test set accuracies against OOB accuracies, adding the line `y = x` to the plot.  

```{r daag_11_05_text_04, echo=TRUE}
plot(oobErr,testErr, xlab="OOB error", ylab="test error", main = "Test set accuracies")
text(x=oobErr, y=testErr, labels=seq(1, length(oobErr), 1), pos=4, offset=0.8, cex=0.8)
abline(0, 1, col="red")
```

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We can see that there isn't any consistent difference in the accuracies, and given a random training/test split, there isn't any reason to expect a consistent difference between OOB accuracy and test accuracy. This is since the points in the graph are always changing position at each repetition and they don't show any pattern in the plot at all, only randomness.

(c) We calculate the error rate for the training data:  

```{r daag_11_05_text_05, echo=TRUE}
randomForest::randomForest(class~ ., data=biops, xtest=biops[,-10], ytest=biops[,10])
```

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The use of training data for testing leads to an error rate that is zero because the model was explicitly trained to reduce at most the error between the predicted labels and the true labels of the training data. Anyway, this tells us that this model is very good at predicting the labels of this specific dataset. But it could perform poorly on another set of data, since it may be overfitting the data at our disposal. That's why the model should always be tested on data that wasn't used for the training phase.


# Exercises from *BC* 

## Exercise 3.2

### Text

***Learning about an exponential mean***  

Suppose a random sample is taken from an *exponential distribution* with mean $\lambda$. If we assign the usual noninformative prior $g(\lambda) \propto \frac{1}{\lambda}$, then the posterior density is given, up to a proportionality constant, by
$$
g(\lambda|\text{data}) \propto \lambda^{−n−1} \ e^{−s/\lambda}
$$
where $n$ is the sample size and $s$ is the sum of the observations.  


a) Show that if we transform $\lambda$ to $\theta$ = $\frac{1}{\lambda}$, then $\theta$ has a *gamma density* with shape parameter $n$ and rate parameter $s$. (A gamma density with
shape $\alpha$ and rate $\beta$ is proportional to $h(x) = x^{\alpha−1} e^{−\beta x}$.)  


b) In a life-testing illustration, five bulbs are tested with observed burn times (in hours) of
$$751, 594, 1213, 1126, 819$$ Using the $\mathsf{R}$ function $\mathsf{rgamma}$, simulate $1000$ values from the posterior distribution of $\theta$.  


c) By transforming these simulated draws, obtain a simulated sample from the posterior distribution of $\lambda$.  


d) Estimate the posterior probability that $\lambda$ exceeds $1000$ hours.


### Solution

To begin with, in the following analysis we restrict the support of the *exponential distribution* to the *positive reals* $[0,+\infty]$, knowing that it will be otherwise constantly zero anyway.  

With such specification, we know that
$$
\text{Exp}_{\omega}(x) = \omega \ e^{-\omega x}
$$
with *mean* $\text{E}_x[\text{Exp}_{\omega}(x) = \omega \ e^{-\omega x}] \ = \ \frac{1}{\omega}$.  

Knowing that, in our case, it is given that $\text{E}_x[\text{Exp}_{\omega}(x) = \omega \ e^{-\omega x}] \ = \ \frac{1}{\omega} \ = \ \lambda$, the exponential distribution from which the samples are taken will be:
$$
\text{Exp}_{\frac{1}{\lambda}}(x) = \frac{1}{\lambda} \ e^{-\frac{1}{\lambda} x}
$$

#### (a)  

The given posterior distribution is specified, up to a proportionality constant, by the following:
$$
g(\lambda|\text{data}) \propto \lambda^{−n−1} \ e^{−s/\lambda}
$$
As per the *Theorem for the Change of Random Variables*, and by defining the *c.o.v.* $\theta = \frac{1}{\lambda} \rightarrow \lambda = \frac{1}{\theta}$, we obtain (knowing that $\theta > 0$):
$$
\tilde{g}(\theta|\text{data}) \propto \theta^{\ n+1} \ e^{−s\theta} \ \left|{\frac{d\theta^{-1}}{d\theta}}\right| \ = \ \theta^{\ n+1} \ e^{−s\theta} \ \left|{-\theta^{-2}}\right| \ = \ \theta^{\ n-1} \ e^{−s\theta}
$$
*Quod erat demonstrandum.*

#### (b, c, d)  

```{r bc_03_02_01, echo=TRUE}
obs <- c(751, 594, 1213, 1126, 819)    # Observations

s <- sum(obs)                          # Sum of observations
n <- length(obs)                       # Number of observations

replicatesnr <- 1000                   # Number of posterior samples to draw

# Posterior Thetas
theta_sim <- rgamma(replicatesnr, shape=n, rate=s)
hist(theta_sim, breaks=20,
     main="Simulated Thetas",
     xlab="sampled value",
     ylab="occurrencies (of 1000)")

# Posterior Lambdas
lambda_sim <- 1.0/theta_sim
hist(lambda_sim, breaks=16,
     main="Simulated Lambdas",
     xlab="sampled value",
     ylab="occurrencies (of 1000)")

# Estimate of lambda > 1000 | (from the 1000 samples above)
prest_1000 <- sum(lambda_sim > 1000) / replicatesnr    # ~ 0.463


# Estimate of lambda > 1000 | (from n_samples -> +infty)
approx_infty <- 10000000    # The best we can with 16GB RAM (in one run!)
prest_infty <- sum((1.0/rgamma(approx_infty, shape=n, rate=s)) > 1000) / approx_infty    # ~ 0.469

```

### Comments (d)

From the sampling performed above, we can show that the approximation offered by the mentioned $1000$ samples from the posterior of $\lambda$ is sufficient to obtain a $<1\%$-*correct* approximation for the posterior probability that $\lambda > 1000$, being given and fixed all the available observations.

<!-- LEAVE A NEWLINE AT THE END-OF-FILE! -->
